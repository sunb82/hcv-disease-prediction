{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf10ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully\n",
      "Pandas version: 2.3.2\n",
      "Scikit-learn version: 1.7.1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data Preprocessing Pipeline for HCV Disease Prediction\n",
    "========================================================\n",
    "This notebook handles:\n",
    "1. Data cleaning and preparation\n",
    "2. Feature engineering\n",
    "3. Handling class imbalance\n",
    "4. Feature scaling\n",
    "5. Train/test splitting\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn  # Add this import\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)  # For reproducibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Plot settings\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f2be6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INITIAL DATA ASSESSMENT\n",
      "============================================================\n",
      "Dataset shape: (615, 15)\n",
      "\n",
      "Target distribution:\n",
      "Category\n",
      "0=Blood Donor             533\n",
      "0s=suspect Blood Donor      7\n",
      "1=Hepatitis                24\n",
      "2=Fibrosis                 21\n",
      "3=Cirrhosis                30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values: 32\n",
      "\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Load the explored data\n",
    "df = pd.read_csv('../data/hcv_data_explored.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INITIAL DATA ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['Category'].value_counts().sort_index())\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad43c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š CLEANING REPORT:\n",
      "----------------------------------------\n",
      "duplicates_removed: 0\n",
      "missing_values_removed: 26\n",
      "outliers_found: 92\n",
      "\n",
      "Cleaned dataset shape: (589, 15)\n"
     ]
    }
   ],
   "source": [
    "class DataCleaner:\n",
    "    \"\"\"Handle data cleaning operations\"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.cleaning_report = {}\n",
    "    \n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"Remove duplicate rows\"\"\"\n",
    "        initial_shape = self.df.shape[0]\n",
    "        self.df = self.df.drop_duplicates()\n",
    "        removed = initial_shape - self.df.shape[0]\n",
    "        self.cleaning_report['duplicates_removed'] = removed\n",
    "        return self\n",
    "    \n",
    "    def handle_missing_values(self, strategy='drop'):\n",
    "        \"\"\"Handle missing values with specified strategy\"\"\"\n",
    "        if strategy == 'drop':\n",
    "            initial_shape = self.df.shape[0]\n",
    "            self.df = self.df.dropna()\n",
    "            removed = initial_shape - self.df.shape[0]\n",
    "            self.cleaning_report['missing_values_removed'] = removed\n",
    "        return self\n",
    "    \n",
    "    def handle_outliers(self, columns=None, n_std=3):\n",
    "        \"\"\"Remove outliers beyond n standard deviations\"\"\"\n",
    "        if columns is None:\n",
    "            # Get numeric columns\n",
    "            columns = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            # Remove 'Category' if it exists in the list\n",
    "            if 'Category' in columns:\n",
    "                columns.remove('Category')\n",
    "        \n",
    "        outliers_removed = 0\n",
    "        for col in columns:\n",
    "            mean = self.df[col].mean()\n",
    "            std = self.df[col].std()\n",
    "            \n",
    "            # Define outlier boundaries\n",
    "            lower_bound = mean - n_std * std\n",
    "            upper_bound = mean + n_std * std\n",
    "            \n",
    "            # Count outliers\n",
    "            outliers = self.df[(self.df[col] < lower_bound) | (self.df[col] > upper_bound)]\n",
    "            outliers_removed += len(outliers)\n",
    "            \n",
    "            # Remove outliers (optional - comment out if you want to keep them)\n",
    "            # self.df = self.df[(self.df[col] >= lower_bound) & (self.df[col] <= upper_bound)]\n",
    "        \n",
    "        self.cleaning_report['outliers_found'] = outliers_removed\n",
    "        return self\n",
    "    \n",
    "    def get_clean_data(self):\n",
    "        \"\"\"Return cleaned dataframe\"\"\"\n",
    "        print(\"\\nðŸ“Š CLEANING REPORT:\")\n",
    "        print(\"-\" * 40)\n",
    "        for key, value in self.cleaning_report.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        return self.df\n",
    "\n",
    "# Apply cleaning\n",
    "cleaner = DataCleaner(df)\n",
    "df_clean = cleaner.remove_duplicates().handle_missing_values().handle_outliers().get_clean_data()\n",
    "print(f\"\\nCleaned dataset shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd15acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
